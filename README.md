# UniSparse: An Intermediate Language for General Sparse Format Customization




## Introduction  
UniSparse is an intermediate language and compiler that provides a unified abstraction for representing and customizing sparse formats. Compared to prior sparse linear algebra compilers, UniSparse decouples the logical representation of the sparse tensor (i.e., the data structure) from its low-level memory layout, enabling the customization of both. UniSparse improves over current programming models that only provide limited support for customized sparse formats.

This repository implements UniSparse as an independent dialect on top of the MLIR infrastructure. The UniSparse  dialect allows users to declaratively specify format conversion and compute kernels using UniSparse format encodings. The compiler tool automatically lowers the program and generates format conversion routines and sparse linear algebra kernels.

This artifact supports the evaluation claim in the paper #18 of OOPSLA'24:
  - The format conversion and compute kernels generated by UniSparse achieve performance that matches prior MLIR SparseTensor and TACO compilers, while provides a broader coverage for handling a wider range of custom formats. (Section 7.3 and 7.4)

In the Step-by-Step Instructions section below, we provide instructions for 2 experiments. Experiment 1 and 2 reproduces the performance numbers in Section 7.3 and 7.4 respectively, which support the claim. We omit the experiments in Section 7.2 as they require multi-core CPUs and GPUs. We provide fewer datasets for each experiment than the paper presents, as more datasets make the docker image big and slow down the set up time.
<!-- Experiment 3 reproduces the performance numbers in Section 7.2.1, which supports claim 2. Experiment 4 reproduces the performance numbers in Section 7.2.2, which also supports claim 2. Experiment 4 is optional depending on whether the evaluator has an NVIDIA GPU and CUDA version >= 11.0. We use 4 datasets for each experiment, as more datasets make the docker image big and slow down the set up time. -->

## Hardware Dependencies

To run experiments 1 and 2, an Intel CPU will work.
<!-- 2. To run experiment 3, our original experiment uses a 48-core Intel Xeon Gold 6248R CPU at 3.00GHz, while we belive a multi-core Intel CPU should work;
3. To run experiment 4, our original experiment uses an NVIDIA RTX A6000 GPU, while we believe an NVIDIA GPU in general will work. -->

## Getting Started
We first pull a docker image from dockerhub:  
`docker pull sibylau/mlir-llvm:oopsla24-ae`  
It may take ~5mins to download the docker image.  
Then we run a container from this docker image:  
`docker run -it --entrypoint bash sibylau/mlir-llvm:oopsla24-ae`  
Inside this container, we clone the UniSparse repo:  
`git clone https://github.com/cornell-zhang/UniSparse.git -b oopsla24-ae`  
Source the bash file under the UniSparse project directory path:  
`$cd UniSparse && source script/build.sh`


## Step-by-Step Instructions
### Experiment 1


### Experiment 2
cd 

### Experiment 3

### Experiment 4

## Reusability Guide



## Building

<!-- This setup assumes that you have built LLVM and MLIR in `$BUILD_DIR` and installed them to `$PREFIX`. To build and launch the tests, run
```sh
mkdir build && cd build
cmake -G Ninja .. -DMLIR_DIR=$PREFIX/lib/cmake/mlir -DLLVM_EXTERNAL_LIT=$BUILD_DIR/bin/llvm-lit
cmake --build . --target check-standalone
``` -->
This project is dependent on [LLVM](https://github.com/llvm/llvm-project/tree/llvmorg-15.0.0-rc1) 15 and [Eigen](https://gitlab.com/libeigen/eigen/-/releases/3.4.0). Please export the environment variables properly according to your LLVM and Eigen installation paths:

```sh
export LLVM_ROOT=$YOUR_LLVM_ROOT_DIR_PATH
export EIGEN_ROOT=$YOUR_EIGEN_ROOT_DIR_PATH
```

Please modify `scripts/cmake-config.sh` according to your LLVM build path and Eigen install path:
```sh
-DMLIR_DIR="$LLVM_ROOT/build/lib/cmake/mlir" \
-DLLVM_DIR="$LLVM_ROOT/build/lib/cmake/llvm" \
-DLLVM_BUILD_LIBRARY_DIR="$LLVM_ROOT/build" \
-DLLVM_EXTERNAL_LIT="$LLVM_ROOT/build/bin/llvm-lit" \
-DEXTERNAL_INCLUDE_DIRS="$EIGEN_ROOT" \
-DMLIR_LIB_DIR="$LLVM_ROOT/mlir/lib" \
```

Then
```sh
source ./scripts/cmake-config.sh # please change the CMAKE ENV variables to your own path
cd build 
ninja # build the project if you have ninja installed. Otherwise do `cmake --build . `
```

To run the tests, type
```sh
ninja check-unisparse
```

To build the documentation from the TableGen description of the dialect operations, run
```sh
ninja mlir-doc
```
**Note**: Make sure to pass `-DLLVM_INSTALL_UTILS=ON` when building LLVM with CMake in order to install `FileCheck` to the chosen installation prefix.

