# UniSparse: An Intermediate Language for General Sparse Format Customization




## Introduction  
UniSparse is an intermediate language and compiler that provides a unified abstraction for representing and customizing sparse formats. Compared to prior sparse linear algebra compilers, UniSparse decouples the logical representation of the sparse tensor (i.e., the data structure) from its low-level memory layout, enabling the customization of both. UniSparse improves over current programming models that only provide limited support for customized sparse formats.

This repository implements UniSparse as an independent dialect on top of the MLIR infrastructure. The UniSparse  dialect allows users to declaratively specify format conversion and compute kernels using UniSparse format encodings. The compiler tool automatically lowers the program and generates format conversion routines and sparse linear algebra kernels.

This artifact supports evaluation claims in the paper #18 of OOPSLA'24 round 1:
  1. The format conversion and compute kernels generated by UniSparse achieve performance that matches prior MLIR SparseTensor and TACO compilers, while provides a broader coverage for handling a wider range of custom formats. (Section 7.3 and 7.4)
  2. The adoption of custom formats enabled by UniSparse leads to improved performance for common sparse linear algebra kernels on hardware platforms such as an Intel multi-core CPU, an NVIDIA GPU and a simulated PIM device. (Section 7.2)

In the Step-by-Step Instructions section below, we provide instructions on how to generate performance numbers in Section 7.2, 7.3 and 7.4 of the paper that support the claims above. 

## Hardware Dependencies
1. To support claim 1 and run experiments in Section 7.3 and 7.4, an Intel CPU will work;
2. To support claim 2 and run experiments in Section 7.2, we require a 48-core Intel Xeon Gold 6248R CPU at 3.00GHz and an NVIDIA RTX A6000 GPU.

## Getting Started


## Step-by-Step Instructions



## Reusability Guide



## Building

<!-- This setup assumes that you have built LLVM and MLIR in `$BUILD_DIR` and installed them to `$PREFIX`. To build and launch the tests, run
```sh
mkdir build && cd build
cmake -G Ninja .. -DMLIR_DIR=$PREFIX/lib/cmake/mlir -DLLVM_EXTERNAL_LIT=$BUILD_DIR/bin/llvm-lit
cmake --build . --target check-standalone
``` -->
This project is dependent on [LLVM](https://github.com/llvm/llvm-project/tree/llvmorg-15.0.0-rc1) 15 and [Eigen](https://gitlab.com/libeigen/eigen/-/releases/3.4.0). Please export the environment variables properly according to your LLVM and Eigen installation paths:

```sh
export LLVM_ROOT=$YOUR_LLVM_ROOT_DIR_PATH
export EIGEN_ROOT=$YOUR_EIGEN_ROOT_DIR_PATH
```

Please modify `scripts/cmake-config.sh` according to your LLVM build path and Eigen install path:
```sh
-DMLIR_DIR="$LLVM_ROOT/build/lib/cmake/mlir" \
-DLLVM_DIR="$LLVM_ROOT/build/lib/cmake/llvm" \
-DLLVM_BUILD_LIBRARY_DIR="$LLVM_ROOT/build" \
-DLLVM_EXTERNAL_LIT="$LLVM_ROOT/build/bin/llvm-lit" \
-DEXTERNAL_INCLUDE_DIRS="$EIGEN_ROOT" \
-DMLIR_LIB_DIR="$LLVM_ROOT/mlir/lib" \
```

Then
```sh
source ./scripts/cmake-config.sh # please change the CMAKE ENV variables to your own path
cd build 
ninja # build the project if you have ninja installed. Otherwise do `cmake --build . `
```

To run the tests, type
```sh
ninja check-unisparse
```

To build the documentation from the TableGen description of the dialect operations, run
```sh
ninja mlir-doc
```
**Note**: Make sure to pass `-DLLVM_INSTALL_UTILS=ON` when building LLVM with CMake in order to install `FileCheck` to the chosen installation prefix.

